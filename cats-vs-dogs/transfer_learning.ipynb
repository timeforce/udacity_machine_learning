{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications import ResNet50, VGG16, InceptionV3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Apply pre-trained model on training data but with new classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### Steps\n",
    "- Read input：cv2.imread\n",
    "- Change image size：cv2.resize\n",
    "- Define image type：cat = 0, dog = 1\n",
    "- Shuffle the sequence of images and classification：shuffle\n",
    "- Split training set into training and validation sets：train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [04:09<00:00, 50.08it/s] \n",
      "100%|██████████| 12500/12500 [02:23<00:00, 87.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 3.50 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shape = 224 # VGG16 input size = 224*224\n",
    "label = np.array([0] * 12500 + [1] * 12500)\n",
    "data = np.zeros((25000, shape, shape, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(12500)):\n",
    "    img = cv2.imread('./train/cat.%s.jpg' % str(i))\n",
    "    img = img[:, :, ::-1]\n",
    "    data[i] = cv2.resize(img, (shape, shape))\n",
    "    \n",
    "for i in tqdm(range(12500)):\n",
    "    img = cv2.imread('./train/dog.%s.jpg' % str(i))\n",
    "    img = img[:, :, ::-1]\n",
    "    data[i + 12500] = cv2.resize(img, (shape, shape))\n",
    "    \n",
    "print('Training Data Size = %.2f GB' % (sys.getsizeof(data)/1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:26<00:00, 220.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Size = 1.75 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = np.zeros((12500, shape, shape, 3), dtype=np.uint8)\n",
    "for i in tqdm(range(12500)):\n",
    "    img = cv2.imread('./test/%s.jpg' % str(i + 1))\n",
    "    img = img[:, :, ::-1]\n",
    "    test[i] = cv2.resize(img, (shape, shape))\n",
    "print('Testing Data Size = %.2f GB' % (sys.getsizeof(test)/1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the entire pre-trained model plus weights, replace with new classifier.\n",
    "\n",
    "#### Steps\n",
    "- Load pre-trained model and weight, excluding the original classifier\n",
    "- Lock the layers of the pre-trained model to prevent the change during the training process: layers.trainable = False\n",
    "- Add the new classifier to the end of the model. Choose sigmoid or softmax based on the number of types that need to classify\n",
    "- Compire the model.Choose binary_crossentropy or categorical_crossentropy based on the number of types that need to classify\n",
    "- Check the number of trainable weights: create function get_param_count() to count unlocked parameters\n",
    "- Train the model\n",
    "  - Use small batch size so that we can get high precision even with a few epochs\n",
    "  - No need to use too many epochs, 5 ~ 10 is enough. Because the number of trainable parameters is small (~500), it can achieve the optimal without too many epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First I use VGG16 (22 layers) model for transfer learning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def get_params_count(model):\n",
    "    trainable = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    non_trainable = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "    return trainable, non_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Model has 22 layers.\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "y = Dropout(0.5)(base_model.output)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "\n",
    "model1 = Model(inputs=base_model.input, outputs=y)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "print('Model has %d layers.' % len(model1.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 509s - loss: 1.1711 - acc: 0.8045 - val_loss: 0.1745 - val_acc: 0.9540\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 484s - loss: 0.3822 - acc: 0.9157 - val_loss: 0.1281 - val_acc: 0.9636\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 483s - loss: 0.2848 - acc: 0.9304 - val_loss: 0.1187 - val_acc: 0.9658\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 484s - loss: 0.2421 - acc: 0.9394 - val_loss: 0.1072 - val_acc: 0.9662\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 484s - loss: 0.2120 - acc: 0.9415 - val_loss: 0.0973 - val_acc: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a84f0ce50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x=X_train, y=y_train, batch_size=16, epochs=5, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try ResNet50 model (178 layers). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 230, 230, 3)   0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 112, 112, 64)  9472        zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 112, 112, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 55, 55, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 55, 55, 64)    4160        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 55, 55, 256)   16640       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 55, 55, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 55, 55, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 55, 55, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 55, 55, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 55, 55, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 55, 55, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 55, 55, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 28, 28, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 28, 28, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 28, 28, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 28, 28, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 28, 28, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 28, 28, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 28, 28, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 14, 14, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 14, 14, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 14, 14, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 14, 14, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 14, 14, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 14, 14, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 14, 14, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 14, 14, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 14, 14, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 14, 14, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 14, 14, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 14, 14, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 14, 14, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 14, 14, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 7, 7, 512)     524800      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 7, 7, 2048)    2099200     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2048)          0           global_average_pooling2d_2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             2049        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "____________________________________________________________________________________________________\n",
      "Model has 178 layers.\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "y = Dropout(0.25)(base_model.output)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "\n",
    "model2 = Model(inputs=base_model.input, outputs=y)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "print('Model has %d layers.' % len(model2.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 297s - loss: 0.1764 - acc: 0.9321 - val_loss: 0.0751 - val_acc: 0.9748\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 296s - loss: 0.1040 - acc: 0.9605 - val_loss: 0.0639 - val_acc: 0.9766\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 296s - loss: 0.0979 - acc: 0.9624 - val_loss: 0.0603 - val_acc: 0.9770\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 296s - loss: 0.0926 - acc: 0.9644 - val_loss: 0.0574 - val_acc: 0.9776\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 296s - loss: 0.0868 - acc: 0.9657 - val_loss: 0.0566 - val_acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69ca887e50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=X_train, y=y_train, batch_size=16, epochs=5, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Apply pre-trained model on training data with new classifer and fine tune the last several layers\n",
    "\n",
    "#### Steps\n",
    "- Here I use the model2 created above. \n",
    "- Unblock the last several layers and train them.\n",
    "- Since several layers form a combination (e.g. conv + batchNorm + acitvation), we'd better block/unblock the combination.\n",
    "- Unblock the layers from high (output) to low (input). Train 5 epochs when unblocking on part. Then check if the loss and accuracy have improved. If the answer is yes, then we can continue training. Otherwise, we can unblock more layers until the training result has improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Activation at 0x7f69cb4f8bd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb4f8d90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb4c7e90>,\n",
       " <keras.layers.core.Activation at 0x7f69cb498fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb498590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb43c610>,\n",
       " <keras.layers.core.Activation at 0x7f69cb370f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb3b9f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb313ed0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb3dd590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb35be50>,\n",
       " <keras.layers.merge.Add at 0x7f69cb2e6c90>,\n",
       " <keras.layers.core.Activation at 0x7f69cb28df50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb27d950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb20ae50>,\n",
       " <keras.layers.core.Activation at 0x7f69cb1d7e50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb220c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb1c3490>,\n",
       " <keras.layers.core.Activation at 0x7f69cb0fadd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb144dd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb165410>,\n",
       " <keras.layers.merge.Add at 0x7f69cb09dd50>,\n",
       " <keras.layers.core.Activation at 0x7f69cb0e2d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb0e2750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cb034cd0>,\n",
       " <keras.layers.core.Activation at 0x7f69cafbff10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69cb008f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69cafa8550>,\n",
       " <keras.layers.core.Activation at 0x7f69caf60e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f69caf2ac50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f69caf4c4d0>,\n",
       " <keras.layers.merge.Add at 0x7f69cae80e10>,\n",
       " <keras.layers.core.Activation at 0x7f69caec9bd0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f69caec9d90>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f69cae99d90>,\n",
       " <keras.layers.core.Dropout at 0x7f69cad8da50>,\n",
       " <keras.layers.core.Dense at 0x7f69cad8db10>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers[-37:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable = 14453249, Non-Trainable = 9136512\n"
     ]
    }
   ],
   "source": [
    "for layers in model2.layers[-35:]:\n",
    "    layers.trainable = True\n",
    "    \n",
    "print('Trainable = %d, Non-Trainable = %d' % (get_params_count(model2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 294s - loss: 0.0860 - acc: 0.9668 - val_loss: 0.0604 - val_acc: 0.9756\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0870 - acc: 0.9647 - val_loss: 0.0583 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0795 - acc: 0.9698 - val_loss: 0.0535 - val_acc: 0.9788\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0830 - acc: 0.9667 - val_loss: 0.0519 - val_acc: 0.9796\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0841 - acc: 0.9675 - val_loss: 0.0520 - val_acc: 0.9810\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0796 - acc: 0.9687 - val_loss: 0.0518 - val_acc: 0.9788\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0799 - acc: 0.9689 - val_loss: 0.0510 - val_acc: 0.9806\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0802 - acc: 0.9694 - val_loss: 0.0504 - val_acc: 0.9792\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0781 - acc: 0.9680 - val_loss: 0.0495 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 295s - loss: 0.0811 - acc: 0.9698 - val_loss: 0.0496 - val_acc: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a874e7b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=X_train, y=y_train, batch_size=16, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save('ResNet_Finetune_last3_epoch5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Multiple Model Integration\n",
    "\n",
    "#### Steps\n",
    "\n",
    "- Calculate feature vectors: calculate the output value of the entire training set from each model (excluding classifier part).\n",
    "- Merge feature vectors: Merge the feature vectors from multiple models.\n",
    "- Train the classifier\n",
    "- Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate feature vectors\n",
    "\n",
    "- Since I have already read the training and test datasets into memory, I can use model.predict() to get feature vectors directly.\n",
    "- Average speed is 2 mins/per training + test feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def export_gap(MODEL, preprocess=None):\n",
    "    x = Input((224, 224, 3))\n",
    "    if preprocess:\n",
    "        x = Lambda(preprocess)(x)\n",
    "    model = MODEL(input_tensor=x, weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    train_gap = model.predict(data, batch_size=128)\n",
    "    test_gap = model.predict(test, batch_size=128)\n",
    "    \n",
    "    with h5py.File(\"gap_%s.h5\" % MODEL.__name__, 'w') as f:\n",
    "        f.create_dataset('train', data=train_gap)\n",
    "        f.create_dataset('test', data=test_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_gap(VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate feature vectors from different models\n",
    "\n",
    "- Use np.concatenate to integrate vectors on specific dimension.\n",
    "- Feed all feature vectors to the classifier which uses gradient descent to set weights automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Vector Shape for Model #0: (25000, 512)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "for gapfile in ['gap_VGG16.h5', 'gap_ResNet50.h5']:\n",
    "    with h5py.File(gapfile, 'r') as f:\n",
    "        train.append(np.array(f['train']))\n",
    "        test.append(np.array(f['test']))\n",
    "        \n",
    "print('Feature Vector Shape for Model #0:', train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Vector Shape after Merging 2 models: (25000, 2560)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate(train, axis=1)\n",
    "X_test = np.concatenate(test, axis=1)\n",
    "print('Feature Vector Shape after Merging 2 models:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "\n",
    "- We just need to define a simple classifier to classify the feature vectors. The output is 0(cat) or 1(dog).\n",
    "- The input of this model is the merged output of above 3 feature vectors. So the input size is (None, 2048 * 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 2,561\n",
      "Trainable params: 2,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((X_train.shape[1],))\n",
    "x = inputs\n",
    "x = Dropout(0.25)(x)\n",
    "y = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_fusion = Model(inputs=inputs, outputs=y, name='Fusion')\n",
    "model_fusion.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model_fusion.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- The total number of parameters of the model is about 6000 and the structure is very simple. The training time is very short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.4400 - acc: 0.8467 - val_loss: 0.1096 - val_acc: 0.9590\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.1301 - acc: 0.9536 - val_loss: 0.0804 - val_acc: 0.9700\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0870 - acc: 0.9673 - val_loss: 0.0698 - val_acc: 0.9728\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0714 - acc: 0.9741 - val_loss: 0.0625 - val_acc: 0.9738\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0624 - acc: 0.9757 - val_loss: 0.0592 - val_acc: 0.9764\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0590 - acc: 0.9787 - val_loss: 0.0580 - val_acc: 0.9766\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0565 - acc: 0.9783 - val_loss: 0.0567 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0536 - acc: 0.9789 - val_loss: 0.0543 - val_acc: 0.9790\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0499 - acc: 0.9814 - val_loss: 0.0532 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.0475 - acc: 0.9815 - val_loss: 0.0541 - val_acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ddcf99eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fusion.fit(x=X_train, y=y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确的使用Finetune，的确可以达到比特征向量法更好的效果（0.0190 vs 0.0232）。关键在于掌控好学习率随解锁层数的动态变化。\n",
    "Observation\n",
    "\n",
    "We can achieve better result using Fine tuning than feature vectors (0.0496 vs 0.0541). The key point is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set and upload result to Kaggle\n",
    "\n",
    "- The judgment standard is LogLoss.\n",
    "- Kaggle's scoring system will adjust the probability between 10^-15 and 1 - 10^-15)\n",
    "- We change the output from 0/1 to 0.005/0.995 when the output is close to 0 or 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Optimizer weight shape (2048,) not compatible with provided weight shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-19b4bedee3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResNet_Finetune_last3_epoch5.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.995\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0moptimizer_weight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0moptimizer_weight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weight_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Optimizer weight shape (2048,) not compatible with provided weight shape (1,)"
     ]
    }
   ],
   "source": [
    "final_mode = load_model('ResNet_Finetune_last3_epoch5.h5')\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred.shape, y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.csv', 'w') as f:\n",
    "    f.writelines('id,label\\n')\n",
    "    for i in range(12500):\n",
    "        f.writelines(str(i+1) + ',' + str(y_pred[i][0]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
